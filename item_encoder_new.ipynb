{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/200], loss:0.00016564\n",
      "epoch [2/200], loss:0.00015713\n",
      "epoch [3/200], loss:0.00014955\n",
      "epoch [4/200], loss:0.00014281\n",
      "epoch [5/200], loss:0.00013684\n",
      "epoch [6/200], loss:0.00013156\n",
      "epoch [7/200], loss:0.00012689\n",
      "epoch [8/200], loss:0.00012276\n",
      "epoch [9/200], loss:0.00011909\n",
      "epoch [10/200], loss:0.00011582\n",
      "epoch [11/200], loss:0.00011292\n",
      "epoch [12/200], loss:0.00011033\n",
      "epoch [13/200], loss:0.00010803\n",
      "epoch [14/200], loss:0.00010598\n",
      "epoch [15/200], loss:0.00010417\n",
      "epoch [16/200], loss:0.00010256\n",
      "epoch [17/200], loss:0.00010114\n",
      "epoch [18/200], loss:0.00009989\n",
      "epoch [19/200], loss:0.00009879\n",
      "epoch [20/200], loss:0.00009782\n",
      "epoch [21/200], loss:0.00009696\n",
      "epoch [22/200], loss:0.00009621\n",
      "epoch [23/200], loss:0.00009554\n",
      "epoch [24/200], loss:0.00009494\n",
      "epoch [25/200], loss:0.00009440\n",
      "epoch [26/200], loss:0.00009391\n",
      "epoch [27/200], loss:0.00009346\n",
      "epoch [28/200], loss:0.00009305\n",
      "epoch [29/200], loss:0.00009268\n",
      "epoch [30/200], loss:0.00009234\n",
      "epoch [31/200], loss:0.00009202\n",
      "epoch [32/200], loss:0.00009173\n",
      "epoch [33/200], loss:0.00009145\n",
      "epoch [34/200], loss:0.00009119\n",
      "epoch [35/200], loss:0.00009095\n",
      "epoch [36/200], loss:0.00009071\n",
      "epoch [37/200], loss:0.00009048\n",
      "epoch [38/200], loss:0.00009024\n",
      "epoch [39/200], loss:0.00009001\n",
      "epoch [40/200], loss:0.00008976\n",
      "epoch [41/200], loss:0.00008951\n",
      "epoch [42/200], loss:0.00008926\n",
      "epoch [43/200], loss:0.00008899\n",
      "epoch [44/200], loss:0.00008871\n",
      "epoch [45/200], loss:0.00008841\n",
      "epoch [46/200], loss:0.00008811\n",
      "epoch [47/200], loss:0.00008780\n",
      "epoch [48/200], loss:0.00008748\n",
      "epoch [49/200], loss:0.00008715\n",
      "epoch [50/200], loss:0.00008681\n",
      "epoch [51/200], loss:0.00008646\n",
      "epoch [52/200], loss:0.00008637\n",
      "epoch [53/200], loss:0.00008628\n",
      "epoch [54/200], loss:0.00008619\n",
      "epoch [55/200], loss:0.00008609\n",
      "epoch [56/200], loss:0.00008599\n",
      "epoch [57/200], loss:0.00008589\n",
      "epoch [58/200], loss:0.00008579\n",
      "epoch [59/200], loss:0.00008569\n",
      "epoch [60/200], loss:0.00008559\n",
      "epoch [61/200], loss:0.00008549\n",
      "epoch [62/200], loss:0.00008538\n",
      "epoch [63/200], loss:0.00008527\n",
      "epoch [64/200], loss:0.00008517\n",
      "epoch [65/200], loss:0.00008506\n",
      "epoch [66/200], loss:0.00008495\n",
      "epoch [67/200], loss:0.00008484\n",
      "epoch [68/200], loss:0.00008473\n",
      "epoch [69/200], loss:0.00008462\n",
      "epoch [70/200], loss:0.00008450\n",
      "epoch [71/200], loss:0.00008439\n",
      "epoch [72/200], loss:0.00008428\n",
      "epoch [73/200], loss:0.00008416\n",
      "epoch [74/200], loss:0.00008405\n",
      "epoch [75/200], loss:0.00008393\n",
      "epoch [76/200], loss:0.00008381\n",
      "epoch [77/200], loss:0.00008369\n",
      "epoch [78/200], loss:0.00008357\n",
      "epoch [79/200], loss:0.00008345\n",
      "epoch [80/200], loss:0.00008333\n",
      "epoch [81/200], loss:0.00008321\n",
      "epoch [82/200], loss:0.00008308\n",
      "epoch [83/200], loss:0.00008296\n",
      "epoch [84/200], loss:0.00008283\n",
      "epoch [85/200], loss:0.00008271\n",
      "epoch [86/200], loss:0.00008258\n",
      "epoch [87/200], loss:0.00008245\n",
      "epoch [88/200], loss:0.00008232\n",
      "epoch [89/200], loss:0.00008219\n",
      "epoch [90/200], loss:0.00008206\n",
      "epoch [91/200], loss:0.00008193\n",
      "epoch [92/200], loss:0.00008180\n",
      "epoch [93/200], loss:0.00008166\n",
      "epoch [94/200], loss:0.00008153\n",
      "epoch [95/200], loss:0.00008140\n",
      "epoch [96/200], loss:0.00008126\n",
      "epoch [97/200], loss:0.00008112\n",
      "epoch [98/200], loss:0.00008099\n",
      "epoch [99/200], loss:0.00008085\n",
      "epoch [100/200], loss:0.00008071\n",
      "epoch [101/200], loss:0.00008057\n",
      "epoch [102/200], loss:0.00008053\n",
      "epoch [103/200], loss:0.00008050\n",
      "epoch [104/200], loss:0.00008046\n",
      "epoch [105/200], loss:0.00008042\n",
      "epoch [106/200], loss:0.00008039\n",
      "epoch [107/200], loss:0.00008035\n",
      "epoch [108/200], loss:0.00008032\n",
      "epoch [109/200], loss:0.00008028\n",
      "epoch [110/200], loss:0.00008024\n",
      "epoch [111/200], loss:0.00008021\n",
      "epoch [112/200], loss:0.00008017\n",
      "epoch [113/200], loss:0.00008013\n",
      "epoch [114/200], loss:0.00008010\n",
      "epoch [115/200], loss:0.00008006\n",
      "epoch [116/200], loss:0.00008003\n",
      "epoch [117/200], loss:0.00007999\n",
      "epoch [118/200], loss:0.00007995\n",
      "epoch [119/200], loss:0.00007992\n",
      "epoch [120/200], loss:0.00007988\n",
      "epoch [121/200], loss:0.00007984\n",
      "epoch [122/200], loss:0.00007981\n",
      "epoch [123/200], loss:0.00007977\n",
      "epoch [124/200], loss:0.00007973\n",
      "epoch [125/200], loss:0.00007970\n",
      "epoch [126/200], loss:0.00007966\n",
      "epoch [127/200], loss:0.00007962\n",
      "epoch [128/200], loss:0.00007959\n",
      "epoch [129/200], loss:0.00007955\n",
      "epoch [130/200], loss:0.00007951\n",
      "epoch [131/200], loss:0.00007948\n",
      "epoch [132/200], loss:0.00007944\n",
      "epoch [133/200], loss:0.00007940\n",
      "epoch [134/200], loss:0.00007937\n",
      "epoch [135/200], loss:0.00007933\n",
      "epoch [136/200], loss:0.00007929\n",
      "epoch [137/200], loss:0.00007925\n",
      "epoch [138/200], loss:0.00007922\n",
      "epoch [139/200], loss:0.00007918\n",
      "epoch [140/200], loss:0.00007914\n",
      "epoch [141/200], loss:0.00007911\n",
      "epoch [142/200], loss:0.00007907\n",
      "epoch [143/200], loss:0.00007903\n",
      "epoch [144/200], loss:0.00007900\n",
      "epoch [145/200], loss:0.00007896\n",
      "epoch [146/200], loss:0.00007892\n",
      "epoch [147/200], loss:0.00007888\n",
      "epoch [148/200], loss:0.00007885\n",
      "epoch [149/200], loss:0.00007881\n",
      "epoch [150/200], loss:0.00007877\n",
      "epoch [151/200], loss:0.00007873\n",
      "epoch [152/200], loss:0.00007873\n",
      "epoch [153/200], loss:0.00007872\n",
      "epoch [154/200], loss:0.00007871\n",
      "epoch [155/200], loss:0.00007870\n",
      "epoch [156/200], loss:0.00007869\n",
      "epoch [157/200], loss:0.00007868\n",
      "epoch [158/200], loss:0.00007867\n",
      "epoch [159/200], loss:0.00007866\n",
      "epoch [160/200], loss:0.00007865\n",
      "epoch [161/200], loss:0.00007864\n",
      "epoch [162/200], loss:0.00007863\n",
      "epoch [163/200], loss:0.00007862\n",
      "epoch [164/200], loss:0.00007861\n",
      "epoch [165/200], loss:0.00007860\n",
      "epoch [166/200], loss:0.00007859\n",
      "epoch [167/200], loss:0.00007859\n",
      "epoch [168/200], loss:0.00007858\n",
      "epoch [169/200], loss:0.00007857\n",
      "epoch [170/200], loss:0.00007856\n",
      "epoch [171/200], loss:0.00007855\n",
      "epoch [172/200], loss:0.00007854\n",
      "epoch [173/200], loss:0.00007853\n",
      "epoch [174/200], loss:0.00007852\n",
      "epoch [175/200], loss:0.00007851\n",
      "epoch [176/200], loss:0.00007850\n",
      "epoch [177/200], loss:0.00007849\n",
      "epoch [178/200], loss:0.00007848\n",
      "epoch [179/200], loss:0.00007847\n",
      "epoch [180/200], loss:0.00007846\n",
      "epoch [181/200], loss:0.00007845\n",
      "epoch [182/200], loss:0.00007845\n",
      "epoch [183/200], loss:0.00007844\n",
      "epoch [184/200], loss:0.00007843\n",
      "epoch [185/200], loss:0.00007842\n",
      "epoch [186/200], loss:0.00007841\n",
      "epoch [187/200], loss:0.00007840\n",
      "epoch [188/200], loss:0.00007839\n",
      "epoch [189/200], loss:0.00007838\n",
      "epoch [190/200], loss:0.00007837\n",
      "epoch [191/200], loss:0.00007836\n",
      "epoch [192/200], loss:0.00007835\n",
      "epoch [193/200], loss:0.00007834\n",
      "epoch [194/200], loss:0.00007833\n",
      "epoch [195/200], loss:0.00007832\n",
      "epoch [196/200], loss:0.00007831\n",
      "epoch [197/200], loss:0.00007831\n",
      "epoch [198/200], loss:0.00007830\n",
      "epoch [199/200], loss:0.00007829\n",
      "epoch [200/200], loss:0.00007828\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "from Models.Models import AutoEncoder\n",
    "\n",
    "class VectorDataset(Dataset):\n",
    "    \"\"\"\n",
    "    reads user or item vector datasets\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path, 'r') as fp:\n",
    "            self.data = json.load(fp)\n",
    "            self.key = list(self.data.keys())\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[self.key[index]]\n",
    "        data = torch.Tensor(data)\n",
    "        #data1 = self.normalize_data(data1)\n",
    "        #data2 = torch.Tensor(data[143:])\n",
    "        #data2 = self.normalize_data(data2)\n",
    "        #data = torch.cat((data1, data2))\n",
    "        return data\n",
    "    \n",
    "    def normalize_data(self, data):\n",
    "        data = F.normalize(data, dim=0)\n",
    "        return data\n",
    "        \n",
    "    def __len__(self):\n",
    "        data_len = len(self.key)\n",
    "        return data_len\n",
    "    \n",
    "\n",
    "test = VectorDataset('./datasets/item_vectors_tf_idf.json')\n",
    "\n",
    "\n",
    "num_epochs = 200\n",
    "batch_size = 143\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = test\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "model = AutoEncoder(input_len=143, hidden_unit=8).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = scheduler.MultiStepLR(optimizer, [50, 100, 150], gamma=0.25)\n",
    "\n",
    "loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for data in dataloader:\n",
    "        scheduler.step()\n",
    "        data = data.to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.8f}'\n",
    "          .format(epoch + 1, num_epochs, running_loss/143))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './trained_model/item_encoder2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
