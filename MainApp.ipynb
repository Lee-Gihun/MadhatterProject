{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "from bs4 import BeautifulSoup\n",
    "from Models.DataCollector import DataCollector\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInspector(DataCollector):\n",
    "    def __init__(self):\n",
    "        self.name_to_key = {}\n",
    "        self.name_to_id = {}\n",
    "        self.id_to_key = {}\n",
    "        self.key_to_id = {}\n",
    "        with open('./metadata/name_to_key.json', 'r') as fp:\n",
    "            self.name_to_key = json.load(fp)\n",
    "\n",
    "        with open('./metadata/name_to_id.json', 'r') as fp:\n",
    "            self.name_to_id = json.load(fp)\n",
    "\n",
    "        with open('./metadata/id_to_key.json', 'r') as fp:\n",
    "            self.id_to_key = json.load(fp)\n",
    "\n",
    "        with open('./metadata/key_to_id.json', 'r') as fp:\n",
    "            self.key_to_id = json.load(fp)\n",
    "\n",
    "    def user_history_collector(self, userName):\n",
    "        # url encoding (for Korean words)\n",
    "        userName = parse.quote(userName)\n",
    "\n",
    "        # open url and create bs4 Object\n",
    "        html = urlopen(\"https://www.op.gg/summoner/userName=\"+userName)\n",
    "        bsObject = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        # decode userName from url encoding\n",
    "        userName = parse.unquote(userName)\n",
    "\n",
    "        # win/loss and play count\n",
    "        wins = int(bsObject.find('span', 'wins').text[:-1])\n",
    "        losses = int(bsObject.find('span', 'losses').text[:-1])\n",
    "        total_play = wins + losses    \n",
    "        win_rate = round(wins/total_play, 3)\n",
    "\n",
    "        champ_list = bsObject.find_all(\"div\", {'class' : 'ChampionBox Ranked'})\n",
    "        champion_history = self.champ_history_setter(champ_list)            \n",
    "\n",
    "        # this is (adapted) user_history DTO\n",
    "        user_historyDTO = {\n",
    "            'user_name' : userName,\n",
    "            'total_play' : total_play,\n",
    "            'win_rate' : win_rate,\n",
    "            'champion_history' : champion_history,\n",
    "        }\n",
    "        return user_historyDTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from Models.Models import AutoEncoder, Predictor\n",
    "from utils import champ_id_remap, global_win_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChampionRecommender():\n",
    "    def __init__(self):\n",
    "        self.user_inspector = UserInspector()\n",
    "\n",
    "        self.user_encoder = AutoEncoder(143, 12)\n",
    "        self.user_encoder.load_state_dict(torch.load('./trained_model/user_encoder_augmented.pth'))\n",
    "\n",
    "        self.item_encoder = AutoEncoder(143, 10)\n",
    "        self.item_encoder.load_state_dict(torch.load('./trained_model/item_encoder.pth'))\n",
    "\n",
    "        self.predictor = Predictor(user_len=12, item_len=10, hidden_unit=22)\n",
    "        self.predictor.load_state_dict(torch.load('./trained_model/predictor_augmented.pth'))\n",
    "        \n",
    "        self.remapped_champ_id = champ_id_remap()\n",
    "        self.global_win_rate = global_win_rate() \n",
    "        \n",
    "        with open('./datasets/item_vectors_tf_idf.json', 'r') as fp:\n",
    "            self.item_vectors = json.load(fp)        \n",
    "        \n",
    "        with open('./metadata/user_idf_table.json', 'r') as fp:\n",
    "            self.idf_table = json.load(fp)\n",
    "\n",
    "    def _recommender(self, userName):\n",
    "        #try:\n",
    "        user_data = self.user_inspector.user_history_collector(userName)\n",
    "        win_rate_dict = self._winrate_predictior(user_data)\n",
    "        return win_rate_dict\n",
    "        #except:\n",
    "        #    print(\"not a valid user. please check.\")\n",
    "\n",
    "\n",
    "    def _winrate_predictior(self, user_data):\n",
    "        user_winrate = self._tensor_item(user_data['win_rate'])\n",
    "        user_vec = self._user_vector_generator(user_data)\n",
    "        played_champions = [i for i, e in enumerate(user_vec) if e != 0]\n",
    "        user_vec = torch.Tensor(user_vec)\n",
    "        user_vec = self.user_encoder.encoder(user_vec)\n",
    "        \n",
    "        win_rate_dict = dict()\n",
    "        \n",
    "        for key, item in self.item_vectors.items():\n",
    "            if key not in played_champions:\n",
    "                global_win = self._tensor_item(self.global_win_rate[int(key)])\n",
    "                item_vec = torch.Tensor([item])\n",
    "                item_vec = self.item_encoder.encoder(item_vec)\n",
    "                item_vec = item_vec.squeeze()\n",
    "                prediction = self.predictor(user_vec, item_vec, user_winrate, global_win)\n",
    "                win_rate_dict[key] = prediction\n",
    "        \n",
    "        return win_rate_dict\n",
    "            \n",
    "            \n",
    "    def _user_vector_generator(self, user_data):\n",
    "        user_win_rate = user_data['win_rate']\n",
    "        play_count_vector = [0 for x in range(143)]\n",
    "\n",
    "        for champ_history in user_data['champion_history']:\n",
    "            original_champ_id = champ_history['champion_key']\n",
    "            champ_idx = self.remapped_champ_id[original_champ_id]\n",
    "\n",
    "            max_play_count = self._get_max_play_count(user_data)\n",
    "            measured_score = (champ_history['play_count'] / max_play_count) * self.idf_table[str(champ_idx)]\n",
    "            play_count_vector[champ_idx] = measured_score\n",
    "        \n",
    "        return play_count_vector\n",
    "\n",
    "    \n",
    "    def _get_max_play_count(self, user_data):\n",
    "        \"\"\"\n",
    "        Get count of maximally played champion for user_name\n",
    "        \"\"\"\n",
    "        max_play_count = 0\n",
    "\n",
    "        for champ_history in user_data['champion_history']:\n",
    "            champ_play_count = champ_history['play_count']\n",
    "            if max_play_count < champ_play_count:\n",
    "                max_play_count = champ_play_count\n",
    "\n",
    "        return max_play_count\n",
    "\n",
    "    \n",
    "    def _tensor_item(self, item):\n",
    "        return torch.Tensor([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ChampionRecommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '1': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '2': tensor([0.5369], grad_fn=<AddBackward0>),\n",
       " '3': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '4': tensor([0.5347], grad_fn=<AddBackward0>),\n",
       " '5': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '6': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '7': tensor([0.5381], grad_fn=<AddBackward0>),\n",
       " '8': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '9': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '10': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '11': tensor([0.5366], grad_fn=<AddBackward0>),\n",
       " '12': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '13': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '14': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '15': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '16': tensor([0.5347], grad_fn=<AddBackward0>),\n",
       " '17': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '18': tensor([0.5346], grad_fn=<AddBackward0>),\n",
       " '19': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '20': tensor([0.5369], grad_fn=<AddBackward0>),\n",
       " '21': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '22': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '23': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '24': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '25': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '26': tensor([0.5351], grad_fn=<AddBackward0>),\n",
       " '27': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '28': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '29': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '30': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '31': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '32': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '33': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '34': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '35': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '36': tensor([0.5366], grad_fn=<AddBackward0>),\n",
       " '37': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '38': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '39': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '40': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '41': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '42': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '43': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '44': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '45': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '46': tensor([0.5366], grad_fn=<AddBackward0>),\n",
       " '47': tensor([0.5350], grad_fn=<AddBackward0>),\n",
       " '48': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '49': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '50': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '51': tensor([0.5347], grad_fn=<AddBackward0>),\n",
       " '52': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '53': tensor([0.5366], grad_fn=<AddBackward0>),\n",
       " '54': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '55': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '56': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '57': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '58': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '59': tensor([0.5347], grad_fn=<AddBackward0>),\n",
       " '60': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '61': tensor([0.5350], grad_fn=<AddBackward0>),\n",
       " '62': tensor([0.5381], grad_fn=<AddBackward0>),\n",
       " '63': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '64': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '65': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '66': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '67': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '68': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '69': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '70': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '71': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '72': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '73': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '74': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '75': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '76': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '77': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '78': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '79': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '80': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '81': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '82': tensor([0.5347], grad_fn=<AddBackward0>),\n",
       " '83': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '84': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '85': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '86': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '87': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '88': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '89': tensor([0.5381], grad_fn=<AddBackward0>),\n",
       " '90': tensor([0.5365], grad_fn=<AddBackward0>),\n",
       " '91': tensor([0.5346], grad_fn=<AddBackward0>),\n",
       " '92': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '93': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '94': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '95': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '96': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '97': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '98': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '99': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '100': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '101': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '102': tensor([0.5346], grad_fn=<AddBackward0>),\n",
       " '103': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '104': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '105': tensor([0.5346], grad_fn=<AddBackward0>),\n",
       " '106': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '107': tensor([0.5347], grad_fn=<AddBackward0>),\n",
       " '108': tensor([0.5369], grad_fn=<AddBackward0>),\n",
       " '109': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '110': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '111': tensor([0.5364], grad_fn=<AddBackward0>),\n",
       " '112': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '113': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '114': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '115': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '116': tensor([0.5368], grad_fn=<AddBackward0>),\n",
       " '117': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '118': tensor([0.5369], grad_fn=<AddBackward0>),\n",
       " '119': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '120': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '121': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '122': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '123': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '124': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '125': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '126': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '127': tensor([0.5366], grad_fn=<AddBackward0>),\n",
       " '128': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '129': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '130': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '131': tensor([0.5369], grad_fn=<AddBackward0>),\n",
       " '132': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '133': tensor([0.5401], grad_fn=<AddBackward0>),\n",
       " '134': tensor([0.5347], grad_fn=<AddBackward0>),\n",
       " '135': tensor([0.5367], grad_fn=<AddBackward0>),\n",
       " '136': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '137': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '138': tensor([0.5348], grad_fn=<AddBackward0>),\n",
       " '139': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '140': tensor([0.5382], grad_fn=<AddBackward0>),\n",
       " '141': tensor([0.5349], grad_fn=<AddBackward0>),\n",
       " '142': tensor([0.5401], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._recommender('만년동핵폭탄')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a.shape) == 1 and len(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
